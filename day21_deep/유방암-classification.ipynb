{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "시드 고정:  12\n"
     ]
    }
   ],
   "source": [
    "# 필수 라이브러리\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "\n",
    "# 랜덤 시드 고정\n",
    "SEED=12\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)  \n",
    "print(\"시드 고정: \", SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 31)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./유방암df.csv')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.8</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.6</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.9</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.8</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.0</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.5</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38           122.8     1001.0          0.11840   \n",
       "1        20.57         17.77           132.9     1326.0          0.08474   \n",
       "2        19.69         21.25           130.0     1203.0          0.10960   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871  ...          17.33            184.6      2019.0   \n",
       "1                 0.05667  ...          23.41            158.8      1956.0   \n",
       "2                 0.05999  ...          25.53            152.5      1709.0   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  label  \n",
       "0          0.4601                  0.11890      0  \n",
       "1          0.2750                  0.08902      0  \n",
       "2          0.3613                  0.08758      0  \n",
       "\n",
       "[3 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.isnull of      mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0          17.99         10.38          122.80     1001.0          0.11840   \n",
       "1          20.57         17.77          132.90     1326.0          0.08474   \n",
       "2          19.69         21.25          130.00     1203.0          0.10960   \n",
       "3          11.42         20.38           77.58      386.1          0.14250   \n",
       "4          20.29         14.34          135.10     1297.0          0.10030   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564        21.56         22.39          142.00     1479.0          0.11100   \n",
       "565        20.13         28.25          131.20     1261.0          0.09780   \n",
       "566        16.60         28.08          108.30      858.1          0.08455   \n",
       "567        20.60         29.33          140.10     1265.0          0.11780   \n",
       "568         7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0             0.27760         0.30010              0.14710         0.2419   \n",
       "1             0.07864         0.08690              0.07017         0.1812   \n",
       "2             0.15990         0.19740              0.12790         0.2069   \n",
       "3             0.28390         0.24140              0.10520         0.2597   \n",
       "4             0.13280         0.19800              0.10430         0.1809   \n",
       "..                ...             ...                  ...            ...   \n",
       "564           0.11590         0.24390              0.13890         0.1726   \n",
       "565           0.10340         0.14400              0.09791         0.1752   \n",
       "566           0.10230         0.09251              0.05302         0.1590   \n",
       "567           0.27700         0.35140              0.15200         0.2397   \n",
       "568           0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "     mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                   0.07871  ...          17.33           184.60      2019.0   \n",
       "1                   0.05667  ...          23.41           158.80      1956.0   \n",
       "2                   0.05999  ...          25.53           152.50      1709.0   \n",
       "3                   0.09744  ...          26.50            98.87       567.7   \n",
       "4                   0.05883  ...          16.67           152.20      1575.0   \n",
       "..                      ...  ...            ...              ...         ...   \n",
       "564                 0.05623  ...          26.40           166.10      2027.0   \n",
       "565                 0.05533  ...          38.25           155.00      1731.0   \n",
       "566                 0.05648  ...          34.12           126.70      1124.0   \n",
       "567                 0.07016  ...          39.42           184.60      1821.0   \n",
       "568                 0.05884  ...          30.37            59.16       268.6   \n",
       "\n",
       "     worst smoothness  worst compactness  worst concavity  \\\n",
       "0             0.16220            0.66560           0.7119   \n",
       "1             0.12380            0.18660           0.2416   \n",
       "2             0.14440            0.42450           0.4504   \n",
       "3             0.20980            0.86630           0.6869   \n",
       "4             0.13740            0.20500           0.4000   \n",
       "..                ...                ...              ...   \n",
       "564           0.14100            0.21130           0.4107   \n",
       "565           0.11660            0.19220           0.3215   \n",
       "566           0.11390            0.30940           0.3403   \n",
       "567           0.16500            0.86810           0.9387   \n",
       "568           0.08996            0.06444           0.0000   \n",
       "\n",
       "     worst concave points  worst symmetry  worst fractal dimension  label  \n",
       "0                  0.2654          0.4601                  0.11890      0  \n",
       "1                  0.1860          0.2750                  0.08902      0  \n",
       "2                  0.2430          0.3613                  0.08758      0  \n",
       "3                  0.2575          0.6638                  0.17300      0  \n",
       "4                  0.1625          0.2364                  0.07678      0  \n",
       "..                    ...             ...                      ...    ...  \n",
       "564                0.2216          0.2060                  0.07115      0  \n",
       "565                0.1628          0.2572                  0.06637      0  \n",
       "566                0.1418          0.2218                  0.07820      0  \n",
       "567                0.2650          0.4087                  0.12400      0  \n",
       "568                0.0000          0.2871                  0.07039      1  \n",
       "\n",
       "[569 rows x 31 columns]>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    357\n",
       "0    212\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#딥러닝 기본에서는 target이 명목형인 경우, dummy로 만들어줘야 한다.(one-hot인코딩) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data = to_categorical(data['label'])\n",
    "y_data[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>564</td>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>565</td>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>566</td>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>567</td>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>568</td>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0          17.99         10.38          122.80     1001.0          0.11840   \n",
       "1          20.57         17.77          132.90     1326.0          0.08474   \n",
       "2          19.69         21.25          130.00     1203.0          0.10960   \n",
       "3          11.42         20.38           77.58      386.1          0.14250   \n",
       "4          20.29         14.34          135.10     1297.0          0.10030   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564        21.56         22.39          142.00     1479.0          0.11100   \n",
       "565        20.13         28.25          131.20     1261.0          0.09780   \n",
       "566        16.60         28.08          108.30      858.1          0.08455   \n",
       "567        20.60         29.33          140.10     1265.0          0.11780   \n",
       "568         7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0             0.27760         0.30010              0.14710         0.2419   \n",
       "1             0.07864         0.08690              0.07017         0.1812   \n",
       "2             0.15990         0.19740              0.12790         0.2069   \n",
       "3             0.28390         0.24140              0.10520         0.2597   \n",
       "4             0.13280         0.19800              0.10430         0.1809   \n",
       "..                ...             ...                  ...            ...   \n",
       "564           0.11590         0.24390              0.13890         0.1726   \n",
       "565           0.10340         0.14400              0.09791         0.1752   \n",
       "566           0.10230         0.09251              0.05302         0.1590   \n",
       "567           0.27700         0.35140              0.15200         0.2397   \n",
       "568           0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "     mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                   0.07871  ...          17.33           184.60      2019.0   \n",
       "1                   0.05667  ...          23.41           158.80      1956.0   \n",
       "2                   0.05999  ...          25.53           152.50      1709.0   \n",
       "3                   0.09744  ...          26.50            98.87       567.7   \n",
       "4                   0.05883  ...          16.67           152.20      1575.0   \n",
       "..                      ...  ...            ...              ...         ...   \n",
       "564                 0.05623  ...          26.40           166.10      2027.0   \n",
       "565                 0.05533  ...          38.25           155.00      1731.0   \n",
       "566                 0.05648  ...          34.12           126.70      1124.0   \n",
       "567                 0.07016  ...          39.42           184.60      1821.0   \n",
       "568                 0.05884  ...          30.37            59.16       268.6   \n",
       "\n",
       "     worst smoothness  worst compactness  worst concavity  \\\n",
       "0             0.16220            0.66560           0.7119   \n",
       "1             0.12380            0.18660           0.2416   \n",
       "2             0.14440            0.42450           0.4504   \n",
       "3             0.20980            0.86630           0.6869   \n",
       "4             0.13740            0.20500           0.4000   \n",
       "..                ...                ...              ...   \n",
       "564           0.14100            0.21130           0.4107   \n",
       "565           0.11660            0.19220           0.3215   \n",
       "566           0.11390            0.30940           0.3403   \n",
       "567           0.16500            0.86810           0.9387   \n",
       "568           0.08996            0.06444           0.0000   \n",
       "\n",
       "     worst concave points  worst symmetry  worst fractal dimension  label  \n",
       "0                  0.2654          0.4601                  0.11890      0  \n",
       "1                  0.1860          0.2750                  0.08902      0  \n",
       "2                  0.2430          0.3613                  0.08758      0  \n",
       "3                  0.2575          0.6638                  0.17300      0  \n",
       "4                  0.1625          0.2364                  0.07678      0  \n",
       "..                    ...             ...                      ...    ...  \n",
       "564                0.2216          0.2060                  0.07115      0  \n",
       "565                0.1628          0.2572                  0.06637      0  \n",
       "566                0.1418          0.2218                  0.07820      0  \n",
       "567                0.2650          0.4087                  0.12400      0  \n",
       "568                0.0000          0.2871                  0.07039      1  \n",
       "\n",
       "[569 rows x 31 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train시킬 문제\n",
    "X_data = data.loc[:,:'label']\n",
    "X_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 31)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_max스케일링\n",
    "# 피처 스케일링\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler=MinMaxScaler()\n",
    "scaler.fit(X_data)\n",
    "X_data_scaled = scaler.fit_transform(X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.52103744, 0.0226581 , 0.54598853, ..., 0.59846245, 0.41886396,\n",
       "        0.        ],\n",
       "       [0.64314449, 0.27257355, 0.61578329, ..., 0.23358959, 0.22287813,\n",
       "        0.        ],\n",
       "       [0.60149557, 0.3902604 , 0.59574321, ..., 0.40370589, 0.21343303,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.45525108, 0.62123774, 0.44578813, ..., 0.12872068, 0.1519087 ,\n",
       "        0.        ],\n",
       "       [0.64456434, 0.66351031, 0.66553797, ..., 0.49714173, 0.45231536,\n",
       "        0.        ],\n",
       "       [0.03686876, 0.50152181, 0.02853984, ..., 0.25744136, 0.10068215,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(455, 31) (455, 2)\n",
      "(114, 31) (114, 2)\n"
     ]
    }
   ],
   "source": [
    "# train/test data분리\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data_scaled, y_data, \n",
    "                                                    test_size=0.2, \n",
    "                                                    shuffle=True, \n",
    "                                                    random_state=100)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 신경망 모델을 만들어보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델생성\n",
    "# 심층 신경망 모델\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, activation='sigmoid', input_dim = 31))\n",
    "model.add(Dense(64, activation='sigmoid'))\n",
    "model.add(Dense(2, activation='softmax'))#가능성이2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "##이 모델로 설정을 하겠다(compile)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy',#회귀에는 loss옵션값 다르게 줘야함!\n",
    "             metrics=['acc','mae']\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 128)               4096      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,482\n",
      "Trainable params: 12,482\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#설정한 레이어들 요약해서 보기.\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "10/10 - 0s - loss: 0.6652 - acc: 0.6022 - mae: 0.4697 - 371ms/epoch - 37ms/step\n",
      "Epoch 2/200\n",
      "10/10 - 0s - loss: 0.6497 - acc: 0.6418 - mae: 0.4313 - 11ms/epoch - 1ms/step\n",
      "Epoch 3/200\n",
      "10/10 - 0s - loss: 0.6313 - acc: 0.6462 - mae: 0.4638 - 9ms/epoch - 898us/step\n",
      "Epoch 4/200\n",
      "10/10 - 0s - loss: 0.6020 - acc: 0.6418 - mae: 0.4385 - 11ms/epoch - 1ms/step\n",
      "Epoch 5/200\n",
      "10/10 - 0s - loss: 0.5812 - acc: 0.6418 - mae: 0.4189 - 9ms/epoch - 898us/step\n",
      "Epoch 6/200\n",
      "10/10 - 0s - loss: 0.5559 - acc: 0.7341 - mae: 0.4198 - 12ms/epoch - 1ms/step\n",
      "Epoch 7/200\n",
      "10/10 - 0s - loss: 0.5300 - acc: 0.6571 - mae: 0.3863 - 11ms/epoch - 1ms/step\n",
      "Epoch 8/200\n",
      "10/10 - 0s - loss: 0.4872 - acc: 0.7429 - mae: 0.3684 - 8ms/epoch - 810us/step\n",
      "Epoch 9/200\n",
      "10/10 - 0s - loss: 0.4593 - acc: 0.9604 - mae: 0.3645 - 13ms/epoch - 1ms/step\n",
      "Epoch 10/200\n",
      "10/10 - 0s - loss: 0.4149 - acc: 0.8154 - mae: 0.3186 - 10ms/epoch - 1ms/step\n",
      "Epoch 11/200\n",
      "10/10 - 0s - loss: 0.3648 - acc: 0.9143 - mae: 0.2927 - 9ms/epoch - 898us/step\n",
      "Epoch 12/200\n",
      "10/10 - 0s - loss: 0.3229 - acc: 0.9473 - mae: 0.2646 - 9ms/epoch - 897us/step\n",
      "Epoch 13/200\n",
      "10/10 - 0s - loss: 0.2826 - acc: 0.9516 - mae: 0.2342 - 12ms/epoch - 1ms/step\n",
      "Epoch 14/200\n",
      "10/10 - 0s - loss: 0.2451 - acc: 0.9670 - mae: 0.2064 - 14ms/epoch - 1ms/step\n",
      "Epoch 15/200\n",
      "10/10 - 0s - loss: 0.2132 - acc: 0.9670 - mae: 0.1800 - 9ms/epoch - 898us/step\n",
      "Epoch 16/200\n",
      "10/10 - 0s - loss: 0.1888 - acc: 0.9890 - mae: 0.1638 - 9ms/epoch - 898us/step\n",
      "Epoch 17/200\n",
      "10/10 - 0s - loss: 0.1661 - acc: 0.9692 - mae: 0.1400 - 11ms/epoch - 1ms/step\n",
      "Epoch 18/200\n",
      "10/10 - 0s - loss: 0.1421 - acc: 0.9890 - mae: 0.1239 - 9ms/epoch - 898us/step\n",
      "Epoch 19/200\n",
      "10/10 - 0s - loss: 0.1247 - acc: 0.9868 - mae: 0.1084 - 8ms/epoch - 798us/step\n",
      "Epoch 20/200\n",
      "10/10 - 0s - loss: 0.1123 - acc: 0.9912 - mae: 0.0984 - 12ms/epoch - 1ms/step\n",
      "Epoch 21/200\n",
      "10/10 - 0s - loss: 0.0973 - acc: 0.9912 - mae: 0.0858 - 10ms/epoch - 997us/step\n",
      "Epoch 22/200\n",
      "10/10 - 0s - loss: 0.0880 - acc: 0.9934 - mae: 0.0771 - 7ms/epoch - 698us/step\n",
      "Epoch 23/200\n",
      "10/10 - 0s - loss: 0.0790 - acc: 0.9934 - mae: 0.0695 - 12ms/epoch - 1ms/step\n",
      "Epoch 24/200\n",
      "10/10 - 0s - loss: 0.0718 - acc: 0.9934 - mae: 0.0630 - 10ms/epoch - 997us/step\n",
      "Epoch 25/200\n",
      "10/10 - 0s - loss: 0.0643 - acc: 0.9956 - mae: 0.0572 - 7ms/epoch - 698us/step\n",
      "Epoch 26/200\n",
      "10/10 - 0s - loss: 0.0589 - acc: 0.9956 - mae: 0.0528 - 10ms/epoch - 997us/step\n",
      "Epoch 27/200\n",
      "10/10 - 0s - loss: 0.0560 - acc: 0.9956 - mae: 0.0504 - 10ms/epoch - 997us/step\n",
      "Epoch 28/200\n",
      "10/10 - 0s - loss: 0.0509 - acc: 0.9956 - mae: 0.0453 - 7ms/epoch - 698us/step\n",
      "Epoch 29/200\n",
      "10/10 - 0s - loss: 0.0473 - acc: 0.9978 - mae: 0.0425 - 11ms/epoch - 1ms/step\n",
      "Epoch 30/200\n",
      "10/10 - 0s - loss: 0.0417 - acc: 0.9956 - mae: 0.0375 - 10ms/epoch - 997us/step\n",
      "Epoch 31/200\n",
      "10/10 - 0s - loss: 0.0394 - acc: 0.9956 - mae: 0.0349 - 7ms/epoch - 698us/step\n",
      "Epoch 32/200\n",
      "10/10 - 0s - loss: 0.0393 - acc: 0.9978 - mae: 0.0357 - 11ms/epoch - 1ms/step\n",
      "Epoch 33/200\n",
      "10/10 - 0s - loss: 0.0349 - acc: 0.9978 - mae: 0.0319 - 9ms/epoch - 898us/step\n",
      "Epoch 34/200\n",
      "10/10 - 0s - loss: 0.0312 - acc: 0.9956 - mae: 0.0279 - 7ms/epoch - 698us/step\n",
      "Epoch 35/200\n",
      "10/10 - 0s - loss: 0.0290 - acc: 0.9956 - mae: 0.0260 - 10ms/epoch - 997us/step\n",
      "Epoch 36/200\n",
      "10/10 - 0s - loss: 0.0268 - acc: 0.9978 - mae: 0.0243 - 9ms/epoch - 898us/step\n",
      "Epoch 37/200\n",
      "10/10 - 0s - loss: 0.0250 - acc: 0.9978 - mae: 0.0230 - 7ms/epoch - 698us/step\n",
      "Epoch 38/200\n",
      "10/10 - 0s - loss: 0.0236 - acc: 0.9978 - mae: 0.0217 - 11ms/epoch - 1ms/step\n",
      "Epoch 39/200\n",
      "10/10 - 0s - loss: 0.0221 - acc: 0.9978 - mae: 0.0201 - 11ms/epoch - 1ms/step\n",
      "Epoch 40/200\n",
      "10/10 - 0s - loss: 0.0207 - acc: 0.9978 - mae: 0.0190 - 11ms/epoch - 1ms/step\n",
      "Epoch 41/200\n",
      "10/10 - 0s - loss: 0.0196 - acc: 0.9978 - mae: 0.0181 - 14ms/epoch - 1ms/step\n",
      "Epoch 42/200\n",
      "10/10 - 0s - loss: 0.0191 - acc: 0.9978 - mae: 0.0173 - 9ms/epoch - 897us/step\n",
      "Epoch 43/200\n",
      "10/10 - 0s - loss: 0.0175 - acc: 0.9978 - mae: 0.0161 - 11ms/epoch - 1ms/step\n",
      "Epoch 44/200\n",
      "10/10 - 0s - loss: 0.0166 - acc: 0.9978 - mae: 0.0153 - 9ms/epoch - 898us/step\n",
      "Epoch 45/200\n",
      "10/10 - 0s - loss: 0.0159 - acc: 0.9978 - mae: 0.0147 - 10ms/epoch - 997us/step\n",
      "Epoch 46/200\n",
      "10/10 - 0s - loss: 0.0150 - acc: 0.9978 - mae: 0.0139 - 15ms/epoch - 1ms/step\n",
      "Epoch 47/200\n",
      "10/10 - 0s - loss: 0.0143 - acc: 0.9978 - mae: 0.0132 - 9ms/epoch - 898us/step\n",
      "Epoch 48/200\n",
      "10/10 - 0s - loss: 0.0137 - acc: 0.9978 - mae: 0.0126 - 14ms/epoch - 1ms/step\n",
      "Epoch 49/200\n",
      "10/10 - 0s - loss: 0.0131 - acc: 0.9978 - mae: 0.0120 - 12ms/epoch - 1ms/step\n",
      "Epoch 50/200\n",
      "10/10 - 0s - loss: 0.0124 - acc: 0.9978 - mae: 0.0115 - 14ms/epoch - 1ms/step\n",
      "Epoch 51/200\n",
      "10/10 - 0s - loss: 0.0118 - acc: 0.9978 - mae: 0.0110 - 11ms/epoch - 1ms/step\n",
      "Epoch 52/200\n",
      "10/10 - 0s - loss: 0.0113 - acc: 0.9978 - mae: 0.0105 - 12ms/epoch - 1ms/step\n",
      "Epoch 53/200\n",
      "10/10 - 0s - loss: 0.0109 - acc: 0.9978 - mae: 0.0100 - 10ms/epoch - 997us/step\n",
      "Epoch 54/200\n",
      "10/10 - 0s - loss: 0.0104 - acc: 0.9978 - mae: 0.0096 - 8ms/epoch - 798us/step\n",
      "Epoch 55/200\n",
      "10/10 - 0s - loss: 0.0100 - acc: 0.9978 - mae: 0.0092 - 11ms/epoch - 1ms/step\n",
      "Epoch 56/200\n",
      "10/10 - 0s - loss: 0.0095 - acc: 0.9978 - mae: 0.0089 - 9ms/epoch - 898us/step\n",
      "Epoch 57/200\n",
      "10/10 - 0s - loss: 0.0092 - acc: 1.0000 - mae: 0.0086 - 8ms/epoch - 798us/step\n",
      "Epoch 58/200\n",
      "10/10 - 0s - loss: 0.0088 - acc: 0.9978 - mae: 0.0082 - 10ms/epoch - 997us/step\n",
      "Epoch 59/200\n",
      "10/10 - 0s - loss: 0.0085 - acc: 0.9978 - mae: 0.0079 - 9ms/epoch - 898us/step\n",
      "Epoch 60/200\n",
      "10/10 - 0s - loss: 0.0081 - acc: 1.0000 - mae: 0.0075 - 10ms/epoch - 997us/step\n",
      "Epoch 61/200\n",
      "10/10 - 0s - loss: 0.0079 - acc: 1.0000 - mae: 0.0074 - 8ms/epoch - 798us/step\n",
      "Epoch 62/200\n",
      "10/10 - 0s - loss: 0.0074 - acc: 1.0000 - mae: 0.0070 - 10ms/epoch - 997us/step\n",
      "Epoch 63/200\n",
      "10/10 - 0s - loss: 0.0073 - acc: 1.0000 - mae: 0.0068 - 8ms/epoch - 798us/step\n",
      "Epoch 64/200\n",
      "10/10 - 0s - loss: 0.0070 - acc: 1.0000 - mae: 0.0065 - 9ms/epoch - 898us/step\n",
      "Epoch 65/200\n",
      "10/10 - 0s - loss: 0.0067 - acc: 1.0000 - mae: 0.0063 - 10ms/epoch - 997us/step\n",
      "Epoch 66/200\n",
      "10/10 - 0s - loss: 0.0065 - acc: 1.0000 - mae: 0.0061 - 7ms/epoch - 698us/step\n",
      "Epoch 67/200\n",
      "10/10 - 0s - loss: 0.0063 - acc: 1.0000 - mae: 0.0059 - 11ms/epoch - 1ms/step\n",
      "Epoch 68/200\n",
      "10/10 - 0s - loss: 0.0060 - acc: 1.0000 - mae: 0.0057 - 10ms/epoch - 997us/step\n",
      "Epoch 69/200\n",
      "10/10 - 0s - loss: 0.0059 - acc: 1.0000 - mae: 0.0056 - 7ms/epoch - 698us/step\n",
      "Epoch 70/200\n",
      "10/10 - 0s - loss: 0.0057 - acc: 1.0000 - mae: 0.0054 - 10ms/epoch - 980us/step\n",
      "Epoch 71/200\n",
      "10/10 - 0s - loss: 0.0055 - acc: 1.0000 - mae: 0.0052 - 9ms/epoch - 898us/step\n",
      "Epoch 72/200\n",
      "10/10 - 0s - loss: 0.0054 - acc: 1.0000 - mae: 0.0052 - 7ms/epoch - 698us/step\n",
      "Epoch 73/200\n",
      "10/10 - 0s - loss: 0.0053 - acc: 1.0000 - mae: 0.0051 - 10ms/epoch - 997us/step\n",
      "Epoch 74/200\n",
      "10/10 - 0s - loss: 0.0049 - acc: 1.0000 - mae: 0.0048 - 8ms/epoch - 798us/step\n",
      "Epoch 75/200\n",
      "10/10 - 0s - loss: 0.0048 - acc: 1.0000 - mae: 0.0046 - 7ms/epoch - 698us/step\n",
      "Epoch 76/200\n",
      "10/10 - 0s - loss: 0.0046 - acc: 1.0000 - mae: 0.0044 - 10ms/epoch - 997us/step\n",
      "Epoch 77/200\n",
      "10/10 - 0s - loss: 0.0044 - acc: 1.0000 - mae: 0.0042 - 7ms/epoch - 698us/step\n",
      "Epoch 78/200\n",
      "10/10 - 0s - loss: 0.0043 - acc: 1.0000 - mae: 0.0041 - 8ms/epoch - 798us/step\n",
      "Epoch 79/200\n",
      "10/10 - 0s - loss: 0.0041 - acc: 1.0000 - mae: 0.0040 - 8ms/epoch - 798us/step\n",
      "Epoch 80/200\n",
      "10/10 - 0s - loss: 0.0040 - acc: 1.0000 - mae: 0.0039 - 8ms/epoch - 798us/step\n",
      "Epoch 81/200\n",
      "10/10 - 0s - loss: 0.0039 - acc: 1.0000 - mae: 0.0037 - 9ms/epoch - 898us/step\n",
      "Epoch 82/200\n",
      "10/10 - 0s - loss: 0.0038 - acc: 1.0000 - mae: 0.0037 - 8ms/epoch - 798us/step\n",
      "Epoch 83/200\n",
      "10/10 - 0s - loss: 0.0037 - acc: 1.0000 - mae: 0.0035 - 9ms/epoch - 898us/step\n",
      "Epoch 84/200\n",
      "10/10 - 0s - loss: 0.0036 - acc: 1.0000 - mae: 0.0035 - 9ms/epoch - 898us/step\n",
      "Epoch 85/200\n",
      "10/10 - 0s - loss: 0.0035 - acc: 1.0000 - mae: 0.0034 - 7ms/epoch - 698us/step\n",
      "Epoch 86/200\n",
      "10/10 - 0s - loss: 0.0034 - acc: 1.0000 - mae: 0.0033 - 10ms/epoch - 997us/step\n",
      "Epoch 87/200\n",
      "10/10 - 0s - loss: 0.0033 - acc: 1.0000 - mae: 0.0032 - 9ms/epoch - 898us/step\n",
      "Epoch 88/200\n",
      "10/10 - 0s - loss: 0.0032 - acc: 1.0000 - mae: 0.0031 - 7ms/epoch - 698us/step\n",
      "Epoch 89/200\n",
      "10/10 - 0s - loss: 0.0031 - acc: 1.0000 - mae: 0.0030 - 10ms/epoch - 997us/step\n",
      "Epoch 90/200\n",
      "10/10 - 0s - loss: 0.0031 - acc: 1.0000 - mae: 0.0030 - 8ms/epoch - 798us/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/200\n",
      "10/10 - 0s - loss: 0.0030 - acc: 1.0000 - mae: 0.0029 - 7ms/epoch - 698us/step\n",
      "Epoch 92/200\n",
      "10/10 - 0s - loss: 0.0029 - acc: 1.0000 - mae: 0.0028 - 10ms/epoch - 997us/step\n",
      "Epoch 93/200\n",
      "10/10 - 0s - loss: 0.0028 - acc: 1.0000 - mae: 0.0028 - 8ms/epoch - 798us/step\n",
      "Epoch 94/200\n",
      "10/10 - 0s - loss: 0.0028 - acc: 1.0000 - mae: 0.0027 - 8ms/epoch - 798us/step\n",
      "Epoch 95/200\n",
      "10/10 - 0s - loss: 0.0027 - acc: 1.0000 - mae: 0.0026 - 10ms/epoch - 997us/step\n",
      "Epoch 96/200\n",
      "10/10 - 0s - loss: 0.0027 - acc: 1.0000 - mae: 0.0026 - 8ms/epoch - 798us/step\n",
      "Epoch 97/200\n",
      "10/10 - 0s - loss: 0.0026 - acc: 1.0000 - mae: 0.0025 - 8ms/epoch - 798us/step\n",
      "Epoch 98/200\n",
      "10/10 - 0s - loss: 0.0025 - acc: 1.0000 - mae: 0.0024 - 9ms/epoch - 898us/step\n",
      "Epoch 99/200\n",
      "10/10 - 0s - loss: 0.0024 - acc: 1.0000 - mae: 0.0024 - 8ms/epoch - 798us/step\n",
      "Epoch 100/200\n",
      "10/10 - 0s - loss: 0.0024 - acc: 1.0000 - mae: 0.0023 - 9ms/epoch - 898us/step\n",
      "Epoch 101/200\n",
      "10/10 - 0s - loss: 0.0023 - acc: 1.0000 - mae: 0.0023 - 7ms/epoch - 698us/step\n",
      "Epoch 102/200\n",
      "10/10 - 0s - loss: 0.0023 - acc: 1.0000 - mae: 0.0022 - 9ms/epoch - 897us/step\n",
      "Epoch 103/200\n",
      "10/10 - 0s - loss: 0.0022 - acc: 1.0000 - mae: 0.0022 - 9ms/epoch - 898us/step\n",
      "Epoch 104/200\n",
      "10/10 - 0s - loss: 0.0022 - acc: 1.0000 - mae: 0.0021 - 6ms/epoch - 598us/step\n",
      "Epoch 105/200\n",
      "10/10 - 0s - loss: 0.0021 - acc: 1.0000 - mae: 0.0021 - 10ms/epoch - 997us/step\n",
      "Epoch 106/200\n",
      "10/10 - 0s - loss: 0.0021 - acc: 1.0000 - mae: 0.0020 - 8ms/epoch - 798us/step\n",
      "Epoch 107/200\n",
      "10/10 - 0s - loss: 0.0020 - acc: 1.0000 - mae: 0.0020 - 8ms/epoch - 798us/step\n",
      "Epoch 108/200\n",
      "10/10 - 0s - loss: 0.0020 - acc: 1.0000 - mae: 0.0019 - 10ms/epoch - 997us/step\n",
      "Epoch 109/200\n",
      "10/10 - 0s - loss: 0.0020 - acc: 1.0000 - mae: 0.0019 - 8ms/epoch - 798us/step\n",
      "Epoch 110/200\n",
      "10/10 - 0s - loss: 0.0019 - acc: 1.0000 - mae: 0.0019 - 7ms/epoch - 698us/step\n",
      "Epoch 111/200\n",
      "10/10 - 0s - loss: 0.0019 - acc: 1.0000 - mae: 0.0018 - 9ms/epoch - 898us/step\n",
      "Epoch 112/200\n",
      "10/10 - 0s - loss: 0.0018 - acc: 1.0000 - mae: 0.0018 - 8ms/epoch - 798us/step\n",
      "Epoch 113/200\n",
      "10/10 - 0s - loss: 0.0018 - acc: 1.0000 - mae: 0.0018 - 9ms/epoch - 898us/step\n",
      "Epoch 114/200\n",
      "10/10 - 0s - loss: 0.0017 - acc: 1.0000 - mae: 0.0017 - 8ms/epoch - 798us/step\n",
      "Epoch 115/200\n",
      "10/10 - 0s - loss: 0.0017 - acc: 1.0000 - mae: 0.0017 - 8ms/epoch - 798us/step\n",
      "Epoch 116/200\n",
      "10/10 - 0s - loss: 0.0017 - acc: 1.0000 - mae: 0.0016 - 10ms/epoch - 997us/step\n",
      "Epoch 117/200\n",
      "10/10 - 0s - loss: 0.0016 - acc: 1.0000 - mae: 0.0016 - 7ms/epoch - 698us/step\n",
      "Epoch 118/200\n",
      "10/10 - 0s - loss: 0.0016 - acc: 1.0000 - mae: 0.0016 - 10ms/epoch - 997us/step\n",
      "Epoch 119/200\n",
      "10/10 - 0s - loss: 0.0016 - acc: 1.0000 - mae: 0.0015 - 9ms/epoch - 898us/step\n",
      "Epoch 120/200\n",
      "10/10 - 0s - loss: 0.0015 - acc: 1.0000 - mae: 0.0015 - 7ms/epoch - 698us/step\n",
      "Epoch 121/200\n",
      "10/10 - 0s - loss: 0.0015 - acc: 1.0000 - mae: 0.0015 - 10ms/epoch - 997us/step\n",
      "Epoch 122/200\n",
      "10/10 - 0s - loss: 0.0015 - acc: 1.0000 - mae: 0.0015 - 8ms/epoch - 798us/step\n",
      "Epoch 123/200\n",
      "10/10 - 0s - loss: 0.0015 - acc: 1.0000 - mae: 0.0014 - 7ms/epoch - 698us/step\n",
      "Epoch 124/200\n",
      "10/10 - 0s - loss: 0.0014 - acc: 1.0000 - mae: 0.0014 - 10ms/epoch - 997us/step\n",
      "Epoch 125/200\n",
      "10/10 - 0s - loss: 0.0014 - acc: 1.0000 - mae: 0.0014 - 8ms/epoch - 798us/step\n",
      "Epoch 126/200\n",
      "10/10 - 0s - loss: 0.0014 - acc: 1.0000 - mae: 0.0014 - 8ms/epoch - 798us/step\n",
      "Epoch 127/200\n",
      "10/10 - 0s - loss: 0.0013 - acc: 1.0000 - mae: 0.0013 - 9ms/epoch - 898us/step\n",
      "Epoch 128/200\n",
      "10/10 - 0s - loss: 0.0013 - acc: 1.0000 - mae: 0.0013 - 8ms/epoch - 798us/step\n",
      "Epoch 129/200\n",
      "10/10 - 0s - loss: 0.0013 - acc: 1.0000 - mae: 0.0013 - 9ms/epoch - 898us/step\n",
      "Epoch 130/200\n",
      "10/10 - 0s - loss: 0.0013 - acc: 1.0000 - mae: 0.0013 - 8ms/epoch - 798us/step\n",
      "Epoch 131/200\n",
      "10/10 - 0s - loss: 0.0013 - acc: 1.0000 - mae: 0.0012 - 9ms/epoch - 897us/step\n",
      "Epoch 132/200\n",
      "10/10 - 0s - loss: 0.0012 - acc: 1.0000 - mae: 0.0012 - 11ms/epoch - 1ms/step\n",
      "Epoch 133/200\n",
      "10/10 - 0s - loss: 0.0012 - acc: 1.0000 - mae: 0.0012 - 8ms/epoch - 798us/step\n",
      "Epoch 134/200\n",
      "10/10 - 0s - loss: 0.0012 - acc: 1.0000 - mae: 0.0012 - 10ms/epoch - 997us/step\n",
      "Epoch 135/200\n",
      "10/10 - 0s - loss: 0.0012 - acc: 1.0000 - mae: 0.0012 - 9ms/epoch - 898us/step\n",
      "Epoch 136/200\n",
      "10/10 - 0s - loss: 0.0011 - acc: 1.0000 - mae: 0.0011 - 8ms/epoch - 798us/step\n",
      "Epoch 137/200\n",
      "10/10 - 0s - loss: 0.0011 - acc: 1.0000 - mae: 0.0011 - 10ms/epoch - 997us/step\n",
      "Epoch 138/200\n",
      "10/10 - 0s - loss: 0.0011 - acc: 1.0000 - mae: 0.0011 - 9ms/epoch - 898us/step\n",
      "Epoch 139/200\n",
      "10/10 - 0s - loss: 0.0011 - acc: 1.0000 - mae: 0.0011 - 8ms/epoch - 798us/step\n",
      "Epoch 140/200\n",
      "10/10 - 0s - loss: 0.0011 - acc: 1.0000 - mae: 0.0011 - 10ms/epoch - 997us/step\n",
      "Epoch 141/200\n",
      "10/10 - 0s - loss: 0.0011 - acc: 1.0000 - mae: 0.0010 - 8ms/epoch - 798us/step\n",
      "Epoch 142/200\n",
      "10/10 - 0s - loss: 0.0010 - acc: 1.0000 - mae: 0.0010 - 8ms/epoch - 798us/step\n",
      "Epoch 143/200\n",
      "10/10 - 0s - loss: 0.0010 - acc: 1.0000 - mae: 0.0010 - 11ms/epoch - 1ms/step\n",
      "Epoch 144/200\n",
      "10/10 - 0s - loss: 0.0010 - acc: 1.0000 - mae: 9.9046e-04 - 8ms/epoch - 798us/step\n",
      "Epoch 145/200\n",
      "10/10 - 0s - loss: 9.8431e-04 - acc: 1.0000 - mae: 9.7426e-04 - 8ms/epoch - 798us/step\n",
      "Epoch 146/200\n",
      "10/10 - 0s - loss: 9.7633e-04 - acc: 1.0000 - mae: 9.6660e-04 - 10ms/epoch - 997us/step\n",
      "Epoch 147/200\n",
      "10/10 - 0s - loss: 9.5389e-04 - acc: 1.0000 - mae: 9.4488e-04 - 7ms/epoch - 698us/step\n",
      "Epoch 148/200\n",
      "10/10 - 0s - loss: 9.3867e-04 - acc: 1.0000 - mae: 9.2943e-04 - 23ms/epoch - 2ms/step\n",
      "Epoch 149/200\n",
      "10/10 - 0s - loss: 9.2946e-04 - acc: 1.0000 - mae: 9.1970e-04 - 17ms/epoch - 2ms/step\n",
      "Epoch 150/200\n",
      "10/10 - 0s - loss: 9.1160e-04 - acc: 1.0000 - mae: 9.0248e-04 - 10ms/epoch - 997us/step\n",
      "Epoch 151/200\n",
      "10/10 - 0s - loss: 8.9583e-04 - acc: 1.0000 - mae: 8.8775e-04 - 8ms/epoch - 798us/step\n",
      "Epoch 152/200\n",
      "10/10 - 0s - loss: 8.8200e-04 - acc: 1.0000 - mae: 8.7455e-04 - 8ms/epoch - 798us/step\n",
      "Epoch 153/200\n",
      "10/10 - 0s - loss: 8.6762e-04 - acc: 1.0000 - mae: 8.5966e-04 - 8ms/epoch - 798us/step\n",
      "Epoch 154/200\n",
      "10/10 - 0s - loss: 8.5368e-04 - acc: 1.0000 - mae: 8.4568e-04 - 8ms/epoch - 798us/step\n",
      "Epoch 155/200\n",
      "10/10 - 0s - loss: 8.4082e-04 - acc: 1.0000 - mae: 8.3301e-04 - 9ms/epoch - 898us/step\n",
      "Epoch 156/200\n",
      "10/10 - 0s - loss: 8.2787e-04 - acc: 1.0000 - mae: 8.2028e-04 - 7ms/epoch - 698us/step\n",
      "Epoch 157/200\n",
      "10/10 - 0s - loss: 8.1556e-04 - acc: 1.0000 - mae: 8.0818e-04 - 11ms/epoch - 1ms/step\n",
      "Epoch 158/200\n",
      "10/10 - 0s - loss: 8.0544e-04 - acc: 1.0000 - mae: 7.9832e-04 - 9ms/epoch - 898us/step\n",
      "Epoch 159/200\n",
      "10/10 - 0s - loss: 7.9143e-04 - acc: 1.0000 - mae: 7.8488e-04 - 7ms/epoch - 698us/step\n",
      "Epoch 160/200\n",
      "10/10 - 0s - loss: 7.7898e-04 - acc: 1.0000 - mae: 7.7253e-04 - 10ms/epoch - 997us/step\n",
      "Epoch 161/200\n",
      "10/10 - 0s - loss: 7.6900e-04 - acc: 1.0000 - mae: 7.6263e-04 - 9ms/epoch - 898us/step\n",
      "Epoch 162/200\n",
      "10/10 - 0s - loss: 7.5722e-04 - acc: 1.0000 - mae: 7.5108e-04 - 7ms/epoch - 698us/step\n",
      "Epoch 163/200\n",
      "10/10 - 0s - loss: 7.4848e-04 - acc: 1.0000 - mae: 7.4276e-04 - 11ms/epoch - 1ms/step\n",
      "Epoch 164/200\n",
      "10/10 - 0s - loss: 7.3532e-04 - acc: 1.0000 - mae: 7.2989e-04 - 8ms/epoch - 798us/step\n",
      "Epoch 165/200\n",
      "10/10 - 0s - loss: 7.2675e-04 - acc: 1.0000 - mae: 7.2131e-04 - 9ms/epoch - 898us/step\n",
      "Epoch 166/200\n",
      "10/10 - 0s - loss: 7.2014e-04 - acc: 1.0000 - mae: 7.1496e-04 - 10ms/epoch - 997us/step\n",
      "Epoch 167/200\n",
      "10/10 - 0s - loss: 7.0398e-04 - acc: 1.0000 - mae: 6.9928e-04 - 8ms/epoch - 798us/step\n",
      "Epoch 168/200\n",
      "10/10 - 0s - loss: 6.9345e-04 - acc: 1.0000 - mae: 6.8871e-04 - 8ms/epoch - 798us/step\n",
      "Epoch 169/200\n",
      "10/10 - 0s - loss: 6.8838e-04 - acc: 1.0000 - mae: 6.8326e-04 - 9ms/epoch - 898us/step\n",
      "Epoch 170/200\n",
      "10/10 - 0s - loss: 6.7855e-04 - acc: 1.0000 - mae: 6.7317e-04 - 7ms/epoch - 698us/step\n",
      "Epoch 171/200\n",
      "10/10 - 0s - loss: 6.7050e-04 - acc: 1.0000 - mae: 6.6495e-04 - 9ms/epoch - 898us/step\n",
      "Epoch 172/200\n",
      "10/10 - 0s - loss: 6.6078e-04 - acc: 1.0000 - mae: 6.5545e-04 - 8ms/epoch - 798us/step\n",
      "Epoch 173/200\n",
      "10/10 - 0s - loss: 6.4703e-04 - acc: 1.0000 - mae: 6.4223e-04 - 9ms/epoch - 898us/step\n",
      "Epoch 174/200\n",
      "10/10 - 0s - loss: 6.3802e-04 - acc: 1.0000 - mae: 6.3361e-04 - 9ms/epoch - 898us/step\n",
      "Epoch 175/200\n",
      "10/10 - 0s - loss: 6.2562e-04 - acc: 1.0000 - mae: 6.2184e-04 - 7ms/epoch - 698us/step\n",
      "Epoch 176/200\n",
      "10/10 - 0s - loss: 6.1885e-04 - acc: 1.0000 - mae: 6.1523e-04 - 10ms/epoch - 997us/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 177/200\n",
      "10/10 - 0s - loss: 6.1021e-04 - acc: 1.0000 - mae: 6.0682e-04 - 8ms/epoch - 798us/step\n",
      "Epoch 178/200\n",
      "10/10 - 0s - loss: 6.0261e-04 - acc: 1.0000 - mae: 5.9930e-04 - 8ms/epoch - 798us/step\n",
      "Epoch 179/200\n",
      "10/10 - 0s - loss: 5.9287e-04 - acc: 1.0000 - mae: 5.8958e-04 - 10ms/epoch - 997us/step\n",
      "Epoch 180/200\n",
      "10/10 - 0s - loss: 5.8621e-04 - acc: 1.0000 - mae: 5.8280e-04 - 9ms/epoch - 898us/step\n",
      "Epoch 181/200\n",
      "10/10 - 0s - loss: 5.7857e-04 - acc: 1.0000 - mae: 5.7525e-04 - 7ms/epoch - 698us/step\n",
      "Epoch 182/200\n",
      "10/10 - 0s - loss: 5.6905e-04 - acc: 1.0000 - mae: 5.6587e-04 - 10ms/epoch - 997us/step\n",
      "Epoch 183/200\n",
      "10/10 - 0s - loss: 5.6335e-04 - acc: 1.0000 - mae: 5.6004e-04 - 8ms/epoch - 798us/step\n",
      "Epoch 184/200\n",
      "10/10 - 0s - loss: 5.5487e-04 - acc: 1.0000 - mae: 5.5164e-04 - 8ms/epoch - 798us/step\n",
      "Epoch 185/200\n",
      "10/10 - 0s - loss: 5.4849e-04 - acc: 1.0000 - mae: 5.4535e-04 - 8ms/epoch - 798us/step\n",
      "Epoch 186/200\n",
      "10/10 - 0s - loss: 5.4166e-04 - acc: 1.0000 - mae: 5.3852e-04 - 8ms/epoch - 798us/step\n",
      "Epoch 187/200\n",
      "10/10 - 0s - loss: 5.3509e-04 - acc: 1.0000 - mae: 5.3199e-04 - 9ms/epoch - 898us/step\n",
      "Epoch 188/200\n",
      "10/10 - 0s - loss: 5.2832e-04 - acc: 1.0000 - mae: 5.2525e-04 - 7ms/epoch - 698us/step\n",
      "Epoch 189/200\n",
      "10/10 - 0s - loss: 5.2221e-04 - acc: 1.0000 - mae: 5.1921e-04 - 10ms/epoch - 997us/step\n",
      "Epoch 190/200\n",
      "10/10 - 0s - loss: 5.1510e-04 - acc: 1.0000 - mae: 5.1227e-04 - 9ms/epoch - 898us/step\n",
      "Epoch 191/200\n",
      "10/10 - 0s - loss: 5.0884e-04 - acc: 1.0000 - mae: 5.0601e-04 - 7ms/epoch - 698us/step\n",
      "Epoch 192/200\n",
      "10/10 - 0s - loss: 5.0277e-04 - acc: 1.0000 - mae: 4.9996e-04 - 10ms/epoch - 997us/step\n",
      "Epoch 193/200\n",
      "10/10 - 0s - loss: 4.9411e-04 - acc: 1.0000 - mae: 4.9155e-04 - 7ms/epoch - 698us/step\n",
      "Epoch 194/200\n",
      "10/10 - 0s - loss: 4.8899e-04 - acc: 1.0000 - mae: 4.8651e-04 - 7ms/epoch - 697us/step\n",
      "Epoch 195/200\n",
      "10/10 - 0s - loss: 4.8261e-04 - acc: 1.0000 - mae: 4.8025e-04 - 10ms/epoch - 997us/step\n",
      "Epoch 196/200\n",
      "10/10 - 0s - loss: 4.7747e-04 - acc: 1.0000 - mae: 4.7517e-04 - 9ms/epoch - 898us/step\n",
      "Epoch 197/200\n",
      "10/10 - 0s - loss: 4.7145e-04 - acc: 1.0000 - mae: 4.6945e-04 - 8ms/epoch - 798us/step\n",
      "Epoch 198/200\n",
      "10/10 - 0s - loss: 4.6595e-04 - acc: 1.0000 - mae: 4.6401e-04 - 9ms/epoch - 898us/step\n",
      "Epoch 199/200\n",
      "10/10 - 0s - loss: 4.6005e-04 - acc: 1.0000 - mae: 4.5818e-04 - 8ms/epoch - 798us/step\n",
      "Epoch 200/200\n",
      "10/10 - 0s - loss: 4.5510e-04 - acc: 1.0000 - mae: 4.5322e-04 - 9ms/epoch - 898us/step\n"
     ]
    }
   ],
   "source": [
    "#batch_size는 몇개 학습하고 업데이트하고 다시 학습할것인지 정하는 것\n",
    "history = model.fit(X_train, y_train, epochs=200, batch_size=50, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step - loss: 4.1317e-04 - acc: 1.0000 - mae: 4.1236e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.00041317398427054286, 1.0, 0.000412359629990533]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_result = model.evaluate(X_test, y_test)\n",
    "test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.9997354e-01, 2.6425621e-05], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred0_index = np.argmax(y_pred[0]) \n",
    "y_pred0_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0][5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114, 2)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1,\n",
       "       0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0,\n",
       "       1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1,\n",
       "       0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_test = np.argmax(y_pred, axis= -1)\n",
    "y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1,\n",
       "       0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0,\n",
       "       1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1,\n",
       "       0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_ = np.argmax(y_test, axis= -1)\n",
    "y_test_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "[[49  0]\n",
      " [ 0 65]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "print(accuracy_score(y_test_, y_pred_test))\n",
    "print(confusion_matrix(y_test_, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['mae'])\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['acc'])\n",
    "plt.legend(['mae','loss','acc'])\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

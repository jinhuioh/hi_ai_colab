{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import *\n",
    "##CountVectorizer,TfidfVectorizer 사용, 특성추출\n",
    "#CountVectorizer : 각 텍스트에서 단어 출현 횟수를 카운팅한 벡터\n",
    "#TfidfVectorizer : TF-IDF라는 값을 사용하여 CountVectorizer의 단점을 보완함\n",
    "#                   빈도수와 역빈도수를 함께 고려"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    'you know I want your love',\n",
    "    'I like you',\n",
    "    'what should I do'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "tfidf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 1 0 1 0 1 1]\n",
      " [0 0 1 0 0 0 0 1 0]\n",
      " [1 0 0 0 1 0 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(cv.fit_transform(corpus).toarray())#빈도수기록\n",
    "#DTM(Document Term Matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'you': 7, 'know': 1, 'want': 5, 'your': 8, 'love': 3, 'like': 2, 'what': 6, 'should': 4, 'do': 0}\n"
     ]
    }
   ],
   "source": [
    "print(cv.vocabulary_)#사전의 인덱스와 이름을 확인 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.46735098 0.         0.46735098 0.         0.46735098\n",
      "  0.         0.35543247 0.46735098]\n",
      " [0.         0.         0.79596054 0.         0.         0.\n",
      "  0.         0.60534851 0.        ]\n",
      " [0.57735027 0.         0.         0.         0.57735027 0.\n",
      "  0.57735027 0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(tfidf.fit_transform(corpus).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'you': 7, 'know': 1, 'want': 5, 'your': 8, 'love': 3, 'like': 2, 'what': 6, 'should': 4, 'do': 0}\n"
     ]
    }
   ],
   "source": [
    "print(tfidf.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['know', 'love', 'want', 'you', 'your'], dtype='<U6'),\n",
       " array(['like', 'you'], dtype='<U6'),\n",
       " array(['do', 'should', 'what'], dtype='<U6')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##transform 결과를 역으로 추출\n",
    "cv.inverse_transform(cv.fit_transform(corpus).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['do', 'know', 'like', 'love', 'should', 'want', 'what', 'you', 'your']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.get_feature_names()#단어이름만 찍어보기."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : do\n",
      "1 : know\n",
      "2 : like\n",
      "3 : love\n",
      "4 : should\n",
      "5 : want\n",
      "6 : what\n",
      "7 : you\n",
      "8 : your\n"
     ]
    }
   ],
   "source": [
    "for i, value in enumerate(cv.get_feature_names()):\n",
    "    print(i,':',value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#새로운 문장을 넣어서 어떤 단어들이 들어갔는지 확인해보자.\n",
    "sentence = ['i like like smile want']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 2, 0, 0, 1, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.transform(sentence).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#스팸을 나타내는 사전을 만들어주세요\n",
    "#햄(스팸반대)을 나타내는 사전을 만들어주세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_dict = ['advertise','promotion','sales','hu','special','sale','member',\n",
    "            'news','buy','free']\n",
    "ham_dic = ['order','confirm','agree','check','customer','payment','genetal',\n",
    "           'company','club','send']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "##spam 사전 만들기\n",
    "cv1 = CountVectorizer()\n",
    "tfidf1 = TfidfVectorizer()\n",
    "##ham사전 만들기\n",
    "cv2 = CountVectorizer()\n",
    "tfidf2 = TfidfVectorizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
       "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
       "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
       "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, use_idf=True, vocabulary=None)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv1.fit(spam_dict)\n",
    "tfidf1.fit(spam_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
       "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
       "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
       "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, use_idf=True, vocabulary=None)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.fit(ham_dic)\n",
    "tfidf2.fit(ham_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'advertise': 0,\n",
       " 'promotion': 6,\n",
       " 'sales': 8,\n",
       " 'hu': 3,\n",
       " 'special': 9,\n",
       " 'sale': 7,\n",
       " 'member': 4,\n",
       " 'news': 5,\n",
       " 'buy': 1,\n",
       " 'free': 2}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv1.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'order': 7,\n",
       " 'confirm': 4,\n",
       " 'agree': 0,\n",
       " 'check': 1,\n",
       " 'customer': 5,\n",
       " 'payment': 8,\n",
       " 'genetal': 6,\n",
       " 'company': 3,\n",
       " 'club': 2,\n",
       " 'send': 9}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "email = [\" Promoton! hu good sales sale check payment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 1, 0, 0, 0, 1, 1, 0]], dtype=int64)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result1 = cv1.transform(email).toarray() #spam\n",
    "result1 #2차원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 0, 0, 0, 0, 0, 1, 0]], dtype=int64)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result2 = cv2.transform(email).toarray() #ham\n",
    "result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_feature_list = cv1.get_feature_names()\n",
    "ham_feature_list = cv2.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['advertise', 'buy', 'free', 'hu', 'member', 'news', 'promotion', 'sale', 'sales', 'special']\n",
      "['agree', 'check', 'club', 'company', 'confirm', 'customer', 'genetal', 'order', 'payment', 'send']\n"
     ]
    }
   ],
   "source": [
    "print(spam_feature_list)\n",
    "print(ham_feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 0, 0, 0, 1, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.fit(ham_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'order': 7,\n",
       " 'confirm': 4,\n",
       " 'agree': 0,\n",
       " 'check': 1,\n",
       " 'customer': 5,\n",
       " 'payment': 8,\n",
       " 'genetal': 6,\n",
       " 'company': 3,\n",
       " 'club': 2,\n",
       " 'send': 9}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "result2 = cv.transform(email).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 0, 0, 0, 0, 0, 1, 0]], dtype=int64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_words_count = sum(result1[0]) ## 스팸에 등장하는 단어의 빈도수\n",
    "spam_words_count "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ham_words_count = sum(result2[0])\n",
    "ham_words_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam mail!!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if spam_words_count > ham_words_count:\n",
    "    print('spam mail!!')\n",
    "else:\n",
    "    print('ham mail!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "##문제1. 한글로 사전을 만들어보고 다음을 스팸인지 아닌지 판단해보세요\n",
    "email2 = ['광고!! 허경영 good 세일 확인 지불']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "##문제2. 감정 분류기\n",
    "##긍정/부정 사전을 만들어보세요\n",
    "## input()을 이용해서 문장을 입력받으면, 긍정인지 부정인지 판단해보세요.\n",
    "## if-df vectorizer를 사용해보세요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "##1.\n",
    "spam = ['광고','무료','지불','세일','공짜','무조건','뉴스','행사']\n",
    "ham = ['동의','확인','보냅니다','회사','직원','동료','주문','고객']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#스팸\n",
    "cv3 = CountVectorizer()\n",
    "tfidf3 = TfidfVectorizer()#단어빈도의 가중치 조절\n",
    "#햄\n",
    "cv4 = CountVectorizer()\n",
    "tfidf4 = TfidfVectorizer()#단어빈도의 가중치 조절"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
       "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
       "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
       "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, use_idf=True, vocabulary=None)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#스팸단어들(cv3)을 spam객체에 fit 시켜보자.\n",
    "cv3.fit(spam)\n",
    "tfidf3.fit(spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
       "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
       "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
       "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, use_idf=True, vocabulary=None)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#햄단어들(cv4)을 ham객체에 fit 시켜보자.\n",
    "cv4.fit(ham)\n",
    "tfidf4.fit(ham)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'광고': 1, '무료': 3, '지불': 6, '세일': 5, '공짜': 0, '무조건': 4, '뉴스': 2, '행사': 7}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv3.vocabulary_#spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'동의': 2, '확인': 6, '보냅니다': 3, '회사': 7, '직원': 5, '동료': 1, '주문': 4, '고객': 0}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv4.vocabulary_#ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#이메일이 스팸인지 아닌지 확인해보자!\n",
    "email2 = ['광고!! 허경영 good 세일 확인 지불']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 0, 0, 1, 1, 0]], dtype=int64)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result3 = cv3.transform(email2).toarray()#스팸단어 빈도수 채크!\n",
    "result3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 1, 0]], dtype=int64)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result4 = cv4.transform(email2).toarray()#햄단어 빈도수 채크!\n",
    "result4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_feature_list2 = cv3.get_feature_names()\n",
    "ham_feature_list2 = cv4.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['공짜', '광고', '뉴스', '무료', '무조건', '세일', '지불', '행사']\n",
      "['고객', '동료', '동의', '보냅니다', '주문', '직원', '확인', '회사']\n"
     ]
    }
   ],
   "source": [
    "print(spam_feature_list2)\n",
    "print(ham_feature_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 0, 1, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result3[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#단어의 빈도수를 세어보자!\n",
    "spam_words_count2 = sum(result3[0])\n",
    "spam_words_count2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ham_words_count2 = sum(result4[0])\n",
    "ham_words_count2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam mail!!\n"
     ]
    }
   ],
   "source": [
    "#스팸인지 햄인지 판별!\n",
    "if spam_words_count2 > ham_words_count2:\n",
    "    print('spam mail!!')\n",
    "else:\n",
    "    print('ham mail!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "##문제2. 감정 분류기\n",
    "##긍정/부정 사전을 만들어보세요\n",
    "## input()을 이용해서 문장을 입력받으면, 긍정인지 부정인지 판단해보세요.\n",
    "## if-df vectorizer를 사용해보세요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(1). 사전을 만들기\n",
    "#(2). input 값을 fit 시키기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "feel_good = ['기쁜','행복','웃음','웃다','재미','굿','존잼',\n",
    "             '꿀','멋진','꿀잼','재미있다','행복하다']\n",
    "feel_bad = ['나쁜','싫다','노잼','짜증','졸리다','아깝','나쁨',\n",
    "            '욕','시간아깝다','집가고싶다']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "너의 감정을 이야기해봐: 조금 졸리다. 하지만 재미있고 유익한 시간을 보내고 있어서 행복하다. 꿀잼 ㅎㅎ\n"
     ]
    }
   ],
   "source": [
    "feeling = [input('너의 감정을 이야기해봐: ')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "#긍\n",
    "cv5 = CountVectorizer()\n",
    "tfidf5 = TfidfVectorizer()#단어빈도의 가중치 조절\n",
    "#부\n",
    "cv6 = CountVectorizer()\n",
    "tfidf6 = TfidfVectorizer()#단어빈도의 가중치 조절"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
       "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
       "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
       "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, use_idf=True, vocabulary=None)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#긍정 fit\n",
    "cv5.fit(feel_good)\n",
    "tfidf5.fit(feel_good)\n",
    "#부정 fit\n",
    "cv6.fit(feel_bad)\n",
    "tfidf6.fit(feel_bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'기쁜': 0,\n",
       " '행복': 8,\n",
       " '웃음': 4,\n",
       " '웃다': 3,\n",
       " '재미': 5,\n",
       " '존잼': 7,\n",
       " '멋진': 2,\n",
       " '꿀잼': 1,\n",
       " '재미있다': 6,\n",
       " '행복하다': 9}"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv5.vocabulary_#긍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'나쁜': 0,\n",
       " '싫다': 4,\n",
       " '노잼': 2,\n",
       " '짜증': 8,\n",
       " '졸리다': 6,\n",
       " '아깝': 5,\n",
       " '나쁨': 1,\n",
       " '시간아깝다': 3,\n",
       " '집가고싶다': 7}"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv6.vocabulary_#부"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['조금 졸리다. 하지만 재미있고 유익한 시간을 보내고 있어서 행복하다. 꿀잼 ㅎㅎ']"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 0, 0, 0, 0, 0, 0, 1]], dtype=int64)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#feeling은 꼭 list타입 이어야한다.\n",
    "result5 = cv5.transform(feeling).toarray()#긍정단어 빈도수 채크!\n",
    "result5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 1, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result6 = cv6.transform(feeling).toarray()#부정단어 빈도수 채크!\n",
    "result6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feel_good_count = sum(result5[0])\n",
    "feel_good_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feel_bad_count = sum(result6[0])\n",
    "feel_bad_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "긍정\n"
     ]
    }
   ],
   "source": [
    "if feel_good_count > feel_bad_count:\n",
    "    print('긍정')\n",
    "else:\n",
    "    print('부정')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
